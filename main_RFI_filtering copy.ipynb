{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "96c96541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from tabulate import tabulate\n",
    "from astropy.time import Time\n",
    "from tqdm import tqdm\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import numpy as np\n",
    "from astropy.time import Time\n",
    "import datetime\n",
    "from collections import defaultdict\n",
    "from scipy.spatial import cKDTree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d8c24072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11482838"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_vlass = pd.read_pickle('/datax/scratch/ellambishop/temp_hits_organized/non_vlass_other.pkl')\n",
    "#df_vlass.groupby('tstart').size()\n",
    "df_vlass.columns\n",
    "len(df_vlass)\n",
    "#df_vlass['freq_has_incoherent_counterpart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "295572eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean out initial drift rates=0 and snr > 16\n",
    "def set_filter(file, drift_max=0):\n",
    "    # Load and slice dataset\n",
    "    global df_new\n",
    "    df = file\n",
    "   # print(df.columns)\n",
    "    #small_df = df[start:stop]\n",
    "\n",
    "    # Select relevant columns\n",
    "    columns = ['file_uri', 'observation_id','source_name', 'beam_id', 'ra_hours', 'dec_degrees', 'tstart',\n",
    "               'signal_frequency', 'signal_beam', 'signal_drift_rate', 'signal_snr',\n",
    "               'signal_power', 'signal_incoherent_power', 'signal_num_timesteps','freq_has_incoherent_counterpart', 'freq_has_phase_center_counterpart' ]\n",
    "    df_new = df[columns]\n",
    "\n",
    "    # Apply filtering thresholds\n",
    "    df_new = df_new[(df_new['signal_drift_rate'] != drift_max)]\n",
    "    df_new = df_new[(df_new['signal_snr'])<=16]\n",
    "    df_new['signal_frequency'] = df_new['signal_frequency'].round(3)    \n",
    "    \n",
    "    #print(df_new.groupby('signal_frequency').size())\n",
    "    return df_new\n",
    "\n",
    "#set_filter(df_vlass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e1f9cd70",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfi filtering based on time step- snr ranges and frequency overlap flagging\n",
    "def processing(df):\n",
    "    \"\"\"\n",
    "    Processes filtered DataFrame by grouping on (file_uri, observation_id),\n",
    "    flags RFI based on conditions, and returns the flagged DataFrame.\n",
    "    \"\"\"\n",
    "    # Apply initial filtering\n",
    "    df_new = set_filter(df)\n",
    "\n",
    "    # Group by file_uri and observation_id\n",
    "    grouped = df_new.groupby(['file_uri', 'observation_id'])\n",
    "    flagged_dfs = []\n",
    "\n",
    "    for (file_uri, obs_id), group_df in grouped:\n",
    "        group_df = group_df.copy()\n",
    "        group_df['rfi_flag'] = False\n",
    "        group_df['flag_strength'] = 0\n",
    "\n",
    "        # Conditions to drop hits\n",
    "        cond1 = (\n",
    "            (group_df['signal_num_timesteps'] >= 16) &\n",
    "            (group_df['signal_num_timesteps'] <= 64) &\n",
    "            (group_df['signal_snr'] > 10)\n",
    "        )\n",
    "        cond2 = (\n",
    "            (group_df['signal_num_timesteps'] < 16) &\n",
    "            (group_df['signal_snr'] > 15)\n",
    "        )\n",
    "\n",
    "        drop_mask = cond1 | cond2\n",
    "        group_df = group_df.loc[~drop_mask]\n",
    "\n",
    "        flagged_dfs.append(group_df)\n",
    "\n",
    "    full_df = pd.concat(flagged_dfs, ignore_index=True)\n",
    "    return full_df\n",
    "\n",
    "#full_df = pd.concat(flagged_dfs, ignore_index=True)\n",
    "#processing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "3da5185b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "804791"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df= processing(df_vlass)\n",
    "len(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "17da4120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\n",
      "D      493905\n",
      "A      220656\n",
      "B       47747\n",
      "C       41447\n",
      "BnA      1036\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#convert time to dates and flag the different NRAO configurations \n",
    "\n",
    "# Extended VLA configuration date ranges to fill gaps\n",
    "\n",
    "vla_config_ranges = [\n",
    "    (datetime.date(2023, 1, 19), datetime.date(2023, 5, 29), 'B'),\n",
    "    (datetime.date(2023, 6, 2),  datetime.date(2023, 6, 19), 'BnA'),\n",
    "    (datetime.date(2023, 6, 30), datetime.date(2023, 10, 2), 'A'),\n",
    "    (datetime.date(2023, 10, 3), datetime.date(2023, 10, 19), 'A'),\n",
    "    (datetime.date(2023, 10, 20), datetime.date(2024, 1, 15), 'D'),\n",
    "    (datetime.date(2024, 1, 16), datetime.date(2024, 1, 24), 'D'),   # patch\n",
    "    (datetime.date(2024, 1, 25), datetime.date(2024, 5, 7), 'C'),\n",
    "    (datetime.date(2024, 5, 8),  datetime.date(2024, 9, 16), 'B'),\n",
    "    (datetime.date(2024, 9, 17), datetime.date(2024, 10, 7), 'BnA'),\n",
    "    (datetime.date(2024, 10, 8), datetime.date(2025, 2, 3), 'A'),\n",
    "    (datetime.date(2025, 2, 4), datetime.date(2025, 2, 24), 'A'),     # new patch\n",
    "    (datetime.date(2025, 2, 25), datetime.date(2025, 5, 12), 'D'),\n",
    "    (datetime.date(2025, 5, 13), datetime.date(2025, 5, 21), 'C'),    # patch\n",
    "    (datetime.date(2025, 5, 22), datetime.date(2025, 8, 18), 'C'),\n",
    "    (datetime.date(2025, 8, 19), datetime.date(2025, 9, 2), 'B'),     # patch\n",
    "    (datetime.date(2025, 9, 3),  datetime.date(2026, 1, 20), 'B'),\n",
    "]\n",
    "\n",
    "\n",
    "dates = []\n",
    "configs = []\n",
    "\n",
    "for t in full_df['tstart']:\n",
    "    try:\n",
    "        time = Time(t, format='mjd')\n",
    "        date_str = time.to_value('iso', subfmt='date')\n",
    "        date_obj = datetime.datetime.strptime(date_str, \"%Y-%m-%d\").date()\n",
    "        dates.append(date_str)\n",
    "\n",
    "        matched_config = 'Unknown'\n",
    "        for start, end, config in vla_config_ranges:\n",
    "            if start <= date_obj <= end:\n",
    "                matched_config = config\n",
    "                break\n",
    "        configs.append(matched_config)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"[!] Error parsing tstart={t}: {e}\")\n",
    "        dates.append('Invalid')\n",
    "        configs.append('Unknown')\n",
    "\n",
    "full_df['date'] = dates\n",
    "full_df['config'] = configs\n",
    "\n",
    "print(full_df['config'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "54760ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate and assign the size of the beam for each hit \n",
    "def assign_beam_size_arcsec(full_df):\n",
    "    # Define band frequency ranges (MHz)\n",
    "    band_ranges_mhz = {\n",
    "        'S':  (2000, 4000),   # 3.0 GHz\n",
    "        'C':  (4000, 8000),   # 6.0 GHz\n",
    "        'X':  (8000, 12000),  # 10 GHz\n",
    "        'Ku': ()\n",
    "    }\n",
    "\n",
    "    # Beam size per band and configuration (arcsec)\n",
    "    beam_resolutions = {\n",
    "        'S':  {'D': 23,   'C': 7.0,  'B': 2.1,  'A': 0.65},\n",
    "        'C':  {'D': 12,   'C': 3.5,  'B': 1.0,  'A': 0.33},\n",
    "        'X':  {'D': 7.2,  'C': 2.1,  'B': 0.6,  'A': 0.20},\n",
    "    }\n",
    "\n",
    "    # Build band assignment conditions\n",
    "    conditions = [\n",
    "        (full_df['signal_frequency'] >= 2000) & (full_df['signal_frequency'] < 4000),\n",
    "        (full_df['signal_frequency'] >= 4000) & (full_df['signal_frequency'] < 8000),\n",
    "        (full_df['signal_frequency'] >= 8000) & (full_df['signal_frequency'] < 12000),\n",
    "    ]\n",
    "    band_labels = ['S', 'C', 'X']\n",
    "\n",
    "    # Assign bands\n",
    "    full_df['band'] = np.select(conditions, band_labels, default=None)\n",
    "\n",
    "    # Create lookup dictionary\n",
    "    beam_lookup = {\n",
    "        (band, cfg): size\n",
    "        for band, cfgs in beam_resolutions.items()\n",
    "        for cfg, size in cfgs.items()\n",
    "    }\n",
    "\n",
    "    # Combine band and config as key\n",
    "    full_df['beam_key'] = list(zip(full_df['band'], full_df['config']))\n",
    "\n",
    "    # Assign beam size\n",
    "    full_df['beam_size_arcsec'] = full_df['beam_key'].map(beam_lookup)\n",
    "\n",
    "    return full_df\n",
    "full_df= assign_beam_size_arcsec(full_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "25d23e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_hits_by_beam(df):\n",
    "    import pandas as pd\n",
    "    from collections import defaultdict\n",
    "\n",
    "    grouped_dfs = defaultdict(list)\n",
    "\n",
    "    for fov, group in df.groupby('file_uri'):\n",
    "        # Group by frequency instead of hit ID\n",
    "        beam_counts = group.groupby('signal_frequency')['signal_beam'].nunique()\n",
    "\n",
    "        for freq, n_beams in beam_counts.items():\n",
    "            if n_beams > 5:  # Safety check\n",
    "                continue\n",
    "\n",
    "            hit_group = group[group['signal_frequency'] == freq]\n",
    "            key = f'{n_beams}_beams'\n",
    "            grouped_dfs[key].append(hit_group)\n",
    "\n",
    "    # Combine all groups into DataFrames\n",
    "    for key in grouped_dfs:\n",
    "        grouped_dfs[key] = pd.concat(grouped_dfs[key], ignore_index=True)\n",
    "        #print(f\"Stored {len(grouped_dfs[key])} hits in memory as '{key}'\")\n",
    "\n",
    "    return grouped_dfs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "bc8d490c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups = split_hits_by_beam(full_df)\n",
    "# Combine 1- and 2-beam hits into a single DataFrame\n",
    "df_1_2_beam = pd.concat([df_groups['1_beams'], df_groups['2_beams']], ignore_index=True)\n",
    "\n",
    "# Combine 3-, 4-, and 5-beam hits into a single DataFrame\n",
    "df_3_4_5_beam = pd.concat(\n",
    "    [df_groups['3_beams'], df_groups['4_beams'], df_groups['5_beams']],\n",
    "    ignore_index=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5d04e71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flag overlapping signals in spacially separated beams as rfi, same file uri/fov \n",
    "def flag_local_rfi(df, area_multiplier=3, beam_threshold_fraction=0.75):\n",
    "    from scipy.spatial import ConvexHull\n",
    "    import numpy as np\n",
    "\n",
    "    local_flag_count = 0\n",
    "    df['rfi_flag_local'] = False\n",
    "\n",
    "    unique_freqs = sorted(df['signal_frequency'].unique())\n",
    "\n",
    "    # ⚡ Precompute beam counts per FOV\n",
    "    beam_count_by_fov = df.groupby('file_uri')['signal_beam'].nunique().to_dict()\n",
    "\n",
    "    for freq in unique_freqs:\n",
    "        freq_subset = df[df['signal_frequency'] == freq]\n",
    "\n",
    "        for fov in freq_subset['file_uri'].unique():\n",
    "            subset = freq_subset[freq_subset['file_uri'] == fov]\n",
    "            unique_beams = subset['signal_beam'].unique()\n",
    "\n",
    "            total_beams = beam_count_by_fov.get(fov, 0)\n",
    "            min_required_beams = max(3, int(beam_threshold_fraction * total_beams))\n",
    "\n",
    "            if len(unique_beams) < min_required_beams or len(subset) < 3:\n",
    "                continue\n",
    "\n",
    "            ra0, dec0 = np.mean(subset['ra_hours']), np.mean(subset['dec_degrees'])\n",
    "            ra_offsets = (subset['ra_hours'] - ra0) * 3600 * np.cos(np.deg2rad(dec0))\n",
    "            dec_offsets = (subset['dec_degrees'] - dec0) * 3600\n",
    "            points = np.vstack([ra_offsets, dec_offsets]).T\n",
    "\n",
    "            try:\n",
    "                hull = ConvexHull(points)\n",
    "                hit_area = hull.area\n",
    "            except:\n",
    "                hit_area = 0\n",
    "\n",
    "            avg_beam_size = subset['beam_size_arcsec'].mean()\n",
    "            beam_area = np.pi * (avg_beam_size / 2)**2\n",
    "            threshold_area = area_multiplier * beam_area\n",
    "\n",
    "            if hit_area > threshold_area:\n",
    "                df.loc[subset.index, 'rfi_flag_local'] = True\n",
    "                local_flag_count += len(subset)\n",
    "\n",
    "    return df, local_flag_count\n",
    "\n",
    "\n",
    "\n",
    "df_3_4_5_beam['rfi_flag_local'] = False\n",
    "df_3_4_5_beam, local_count = flag_local_rfi(df_3_4_5_beam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "3d39056c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global RFI flagged: 113630\n"
     ]
    }
   ],
   "source": [
    "#flagging frequencies and drift rates found in same place at dif times/ time persistent rfi \n",
    "def flag_temporal_persistence_rfi(df,\n",
    "                                   frequency_tol=1.0,\n",
    "                                   drift_tol=1.0,\n",
    "                                   radius_multiplier=3,\n",
    "                                   min_time_gap=10,  # seconds\n",
    "                                   min_repeat_count=2,\n",
    "                                   debug=False):\n",
    "    \"\"\"\n",
    "    Flags signals as RFI if they appear at the same sky location (within 3x beam size),\n",
    "    same freq/drift (within tolerance), at different times (≥ min_time_gap),\n",
    "    and occur at least min_repeat_count times.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    df['rfi_flag_global'] = False\n",
    "\n",
    "    df['freq_bin'] = (df['signal_frequency'] / frequency_tol).round().astype(int)\n",
    "    df['drift_bin'] = (df['signal_drift_rate'] / drift_tol).round().astype(int)\n",
    "\n",
    "    dec_mean = df['dec_degrees'].mean()\n",
    "    df['ra_arcsec'] = df['ra_hours'] * 3600 * np.cos(np.deg2rad(dec_mean))\n",
    "    df['dec_arcsec'] = df['dec_degrees'] * 3600\n",
    "\n",
    "    flagged_indices = set()\n",
    "    grouped = df.groupby(['freq_bin', 'drift_bin'])\n",
    "\n",
    "    for (f_bin, d_bin), group in grouped:\n",
    "        if len(group) < min_repeat_count:\n",
    "            continue\n",
    "\n",
    "        coords = group[['ra_arcsec', 'dec_arcsec']].values\n",
    "        beam_sizes = group['beam_size_arcsec'].values\n",
    "        times = group['tstart_datetime'].values\n",
    "        tree = cKDTree(coords)\n",
    "\n",
    "        for i in range(len(group)):\n",
    "            r_i = radius_multiplier * beam_sizes[i]\n",
    "            time_i = times[i]\n",
    "\n",
    "            idx_neighbors = tree.query_ball_point(coords[i], r=r_i)\n",
    "            repeat_times = []\n",
    "\n",
    "            for j in idx_neighbors:\n",
    "                if i == j:\n",
    "                    continue\n",
    "                time_j = times[j]\n",
    "                time_diff = abs(pd.Timedelta(time_i - time_j).total_seconds())\n",
    "                if time_diff >= min_time_gap:\n",
    "                    repeat_times.append(group.index[j])\n",
    "\n",
    "            if len(set(repeat_times)) >= (min_repeat_count - 1):\n",
    "                flagged_indices.add(group.index[i])\n",
    "                flagged_indices.update(repeat_times)\n",
    "\n",
    "    df.loc[list(flagged_indices), 'rfi_flag_global'] = True\n",
    "    return df, len(flagged_indices)\n",
    "\n",
    "df_3_4_5_beam['tstart_datetime'] = Time(df_3_4_5_beam['tstart'], format='mjd').to_datetime()\n",
    "df_3_4_5_beam['rfi_flag_global'] = False\n",
    "df_3_4_5_beam, global_count = flag_temporal_persistence_rfi(df_3_4_5_beam)\n",
    "print(f\"Global RFI flagged: {global_count}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c8647807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temporal persistence global RFI flagged: 113630\n",
      "Multi-FOV freq+drift repeats flagged: 43232\n"
     ]
    }
   ],
   "source": [
    "# Group by freq/drift and count unique FOVs (file_uri) broader global rfi search \n",
    "repeat_groups = df_3_4_5_beam.groupby(['signal_frequency', 'signal_drift_rate'])['file_uri'].nunique()\n",
    "\n",
    "# Find freq/drift pairs appearing in more than one distinct FOV\n",
    "suspect_freqs = repeat_groups[repeat_groups > 1].index\n",
    "\n",
    "# Mark those rows in the dataframe\n",
    "df_3_4_5_beam['global_freq_repeat'] = df_3_4_5_beam.set_index(['signal_frequency', 'signal_drift_rate']).index.isin(suspect_freqs)\n",
    "\n",
    "# Increase flag_strength for these broad repeats\n",
    "df_3_4_5_beam.loc[df_3_4_5_beam['global_freq_repeat'], 'flag_strength'] += 2\n",
    "\n",
    "print(f\"Temporal persistence global RFI flagged: {(df_3_4_5_beam['rfi_flag_global']).sum()}\")\n",
    "print(f\"Multi-FOV freq+drift repeats flagged: {df_3_4_5_beam['global_freq_repeat'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ebfdaef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set all flags within the df \n",
    "def apply_rfi_flagging(df, local_count=None, global_count=None,\n",
    "                       apply_spatial_flags=True,\n",
    "                       apply_power_ratio_flag=True,\n",
    "                       power_ratio_threshold=1.0,\n",
    "                       debug=False):\n",
    "    if local_count is not None:\n",
    "        print(f\"Local RFI flagged:  {local_count}\")\n",
    "    if global_count is not None:\n",
    "        print(f\"Global RFI flagged: {global_count}\")\n",
    "\n",
    "    # Conditions\n",
    "    cond1 = (df['rfi_flag_local']) & (~df['freq_has_incoherent_counterpart']) if apply_spatial_flags else pd.Series(False, index=df.index)\n",
    "    cond2 = (df['signal_power'] > power_ratio_threshold * df['signal_incoherent_power'])\n",
    "    cond2_only = cond2 & (~cond1)\n",
    "    cond3 = df['freq_has_phase_center_counterpart']\n",
    "    global_only = (df['rfi_flag_global']) & (~df['rfi_flag_local']) if apply_spatial_flags else pd.Series(False, index=df.index)\n",
    "\n",
    "    df['rfi_flag'] = False\n",
    "    df['flag_strength'] = 0\n",
    "\n",
    "    if apply_spatial_flags:\n",
    "        df.loc[df['rfi_flag_local'], 'rfi_flag'] = True\n",
    "        df.loc[df['rfi_flag_local'], 'flag_strength'] += 1\n",
    "        df.loc[global_only, 'rfi_flag'] = True\n",
    "        df.loc[global_only, 'flag_strength'] += 1\n",
    "\n",
    "    df.loc[cond1, 'flag_strength'] += 2\n",
    "    df.loc[cond2_only, 'rfi_flag'] = True\n",
    "    df.loc[cond2_only, 'flag_strength'] += 1\n",
    "    df.loc[df['global_freq_repeat'], 'rfi_flag'] = True\n",
    "    df.loc[df['global_freq_repeat'], 'flag_strength'] += 2\n",
    "    df.loc[cond3, 'flag_strength'] += 1\n",
    "\n",
    "    if debug:\n",
    "        print(\"Flag strength distribution:\")\n",
    "        print(df['flag_strength'].value_counts().sort_index())\n",
    "        print(\"Counts for conditions:\")\n",
    "        print(f\"cond1 (local + no incoherent): {cond1.sum()}\")\n",
    "        print(f\"cond2_only (coherent >> incoherent): {cond2_only.sum()}\")\n",
    "        print(f\"global_only (global but not local): {global_only.sum()}\")\n",
    "        print(f\"global_freq_repeat: {df['global_freq_repeat'].sum()}\")\n",
    "        print(f\"cond3 (phase center): {cond3.sum()}\")\n",
    "\n",
    "        # EXTRA: For cases with apply_spatial_flags=False, print cond1 and cond2 counts separately\n",
    "        if not apply_spatial_flags:\n",
    "            print(f\"cond1 total (should be zero): {cond1.sum()}\")  # likely zero here\n",
    "            print(f\"cond2 total: {cond2.sum()}\")\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5246cc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local RFI flagged:  90345\n",
      "Global RFI flagged: 113630\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total detections: 804791\n",
      "Likely clean (flag_strength ≤ 0): 216940\n",
      "Maybe RFI (flag_strength == 1):   511677\n",
      "Strong RFI (flag_strength > 1):   76174\n"
     ]
    }
   ],
   "source": [
    "#split the pickle file into rfi levels for future analysis \n",
    "def split_by_flag_strength(df, clean_thresh=0, maybe_thresh=1):\n",
    "    \"\"\"\n",
    "    Split dataframe into clean, maybe RFI, and strong RFI based on flag_strength thresholds.\n",
    "\n",
    "    - clean_thresh: max flag_strength for 'clean' data (default 0)\n",
    "    - maybe_thresh: max flag_strength for 'maybe' RFI data (default 1)\n",
    "    \"\"\"\n",
    "    clean_df = df[df['flag_strength'] <= clean_thresh]\n",
    "    maybe_rfi_df = df[(df['flag_strength'] > clean_thresh) & (df['flag_strength'] <= maybe_thresh)]\n",
    "    strong_rfi_df = df[df['flag_strength'] > maybe_thresh]\n",
    "    return clean_df, maybe_rfi_df, strong_rfi_df\n",
    "\n",
    "\n",
    "df_3_4_5_beam = apply_rfi_flagging(df_3_4_5_beam, local_count=local_count, global_count=global_count, apply_spatial_flags=True, power_ratio_threshold=2, debug=False)\n",
    "\n",
    "if 'global_freq_repeat' not in df_1_2_beam.columns:\n",
    "    df_1_2_beam['global_freq_repeat'] = False\n",
    "df_1_2_beam = apply_rfi_flagging(df_1_2_beam,apply_spatial_flags=False,power_ratio_threshold=1.25,debug=False)\n",
    "\n",
    "# Combine datasets\n",
    "fin_df = pd.concat([df_1_2_beam, df_3_4_5_beam], ignore_index=True)\n",
    "\n",
    "# Split based on flag strength\n",
    "clean_df, maybe_rfi_df, strong_rfi_df = split_by_flag_strength(fin_df)\n",
    "\n",
    "# Print summary counts\n",
    "print(f\"Total detections: {len(fin_df)}\")\n",
    "print(f\"Likely clean (flag_strength ≤ 0): {len(clean_df)}\")\n",
    "print(f\"Maybe RFI (flag_strength == 1):   {len(maybe_rfi_df)}\")\n",
    "print(f\"Strong RFI (flag_strength > 1):   {len(strong_rfi_df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e5e3650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flag_burst_rfi(df, burst_window=1.0, min_beams=3):\n",
    "    df = df.copy()\n",
    "    df['burst_rfi'] = False\n",
    "    df['timestamp'] = df['tstart_datetime'].astype(np.int64) // 1_000_000_000  # seconds\n",
    "    group = df.groupby(['file_uri', 'signal_frequency', 'timestamp'])\n",
    "    for _, g in group:\n",
    "        if g['signal_beam'].nunique() >= min_beams:\n",
    "            df.loc[g.index, 'burst_rfi'] = True\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4acccb86",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.to_pickle('data/clean_df.pkl')\n",
    "maybe_rfi.to_pickle('data/maybe_rfi.pkl')\n",
    "strong_rfi.to_pickle('data/strong_rfi.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ee6e0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24c2cc40",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
